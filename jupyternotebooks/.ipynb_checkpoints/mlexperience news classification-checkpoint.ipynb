{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuters Data Set\n",
    "Working through Text Mining and Visualization: Case Studies using Open-Source Tools\n",
    "Chapman & Hall/CRC Data Mining and Knowledge Discovery    \n",
    "http://www.nltk.org/book/ch02.html help is available in the nltk book section 1.4\n",
    "http://enricbaltasar.com/python-summary-methods-lists/ help with Python lists\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "Pandas dataframe guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating word popularity in the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import StanfordTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import reuters\n",
    "import os\n",
    "from nltk.parse import stanford\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import RegexpStemmer\n",
    "st = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "snow = EnglishStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#os.environ['STANFORD_PARSER'] = '/Users/David/postagger/stanford-parser-full-2014-08-27/stanford-parser.jar'\n",
    "#os.environ['STANFORD_MODELS'] = '/Users/David/postagger/stanford-parser-full-2014-08-27/stanford-parser-3.4.1-models.jar'\n",
    "#parser = stanford.StanfordParser(model_path=\"/Users/David/postagger/stanford-parser-full-2014-08-27/stanford-parser-3.4.1-models/edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\")\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "#cachedStopWords.append('said')\n",
    " \n",
    "def tokenize(text):\n",
    "    min_length = 3\n",
    "    #tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "    words =  map(lambda word: word.lower(), WordPunctTokenizer().tokenize(text))\n",
    "    #words = list(WhitespaceTokenizer().span_tokenize(text))\n",
    "    #words = map(lambda word: word.lower(), word_tokenize(text));    \n",
    "    #words = wordpunct_tokenize(text)\n",
    "    #word_tokenize = Penn Treebank#\n",
    "    #words = map(lambda word: word.lower(), tokenizer.tokenize(text));\n",
    "    #words = list(parser.raw_parse(text,verbose=False))\n",
    "    #words = map(lambda word: word.lower(), text.split())\n",
    "    words = [word for word in words\n",
    "             if word not in cachedStopWords]\n",
    "    #tokens =(list(map(lambda token: PorterStemmer().stem(token),words)));\n",
    "    #tokens =(list(map(lambda token: LancasterStemmer().stem(token),words)));\n",
    "    #tokens =(list(map(lambda token: snow.stem(token),words)));\n",
    "    #tokens =(list(map(lambda token: st.stem(token),words)));\n",
    "    tokens =(list(map(lambda token: wnl.lemmatize(token),words)));\n",
    "    #tokens=words\n",
    "    p = re.compile('[a-zA-Z]+');\n",
    "    filter_words = list(filter(lambda token: p.match(token) and len(token)>=min_length, tokens));\n",
    "    return filter_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build a data frame to feed the vectorizer\n",
    "category_docs = reuters.fileids();\n",
    "names = ['file_id', 'category','text']\n",
    "file_id = 'x'\n",
    "category = 'x'\n",
    "text = 'x'\n",
    "\n",
    "df = pd.DataFrame([[file_id,category,text]],columns=names)\n",
    "\n",
    "for document_id in category_docs:\n",
    "    text = reuters.raw(document_id)\n",
    "    category =(reuters.categories(document_id))\n",
    "    file_id = (document_id)\n",
    "    temdf = pd.DataFrame([[file_id,category,text]],columns=names)\n",
    "    if (len(category) == 1):\n",
    "        df = df.append(temdf, ignore_index=True)\n",
    "    \n",
    "df['part'] = df['file_id'].apply(lambda x: x[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9161, 4)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9156</th>\n",
       "      <td>training/9988</td>\n",
       "      <td>[interest]</td>\n",
       "      <td>FED SETS TWO BILLION DLR CUSTOMER REPURCHASE\\n...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9157</th>\n",
       "      <td>training/9992</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>KNIGHT-RIDDER INC &amp;lt;KRN&gt; SETS QUARTERLY\\n  Q...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9158</th>\n",
       "      <td>training/9993</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>TECHNITROL INC &amp;lt;TNL&gt; SETS QUARTERLY\\n  Qtly...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9159</th>\n",
       "      <td>training/9994</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>NATIONWIDE CELLULAR SERVICE INC &amp;lt;NCEL&gt; 4TH ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9160</th>\n",
       "      <td>training/9995</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>&amp;lt;A.H.A. AUTOMOTIVE TECHNOLOGIES CORP&gt; YEAR ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_id    category  \\\n",
       "9156  training/9988  [interest]   \n",
       "9157  training/9992      [earn]   \n",
       "9158  training/9993      [earn]   \n",
       "9159  training/9994      [earn]   \n",
       "9160  training/9995      [earn]   \n",
       "\n",
       "                                                   text   part  \n",
       "9156  FED SETS TWO BILLION DLR CUSTOMER REPURCHASE\\n...  train  \n",
       "9157  KNIGHT-RIDDER INC &lt;KRN> SETS QUARTERLY\\n  Q...  train  \n",
       "9158  TECHNITROL INC &lt;TNL> SETS QUARTERLY\\n  Qtly...  train  \n",
       "9159  NATIONWIDE CELLULAR SERVICE INC &lt;NCEL> 4TH ...  train  \n",
       "9160  &lt;A.H.A. AUTOMOTIVE TECHNOLOGIES CORP> YEAR ...  train  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Values for document frequencies in percent.\n",
    "minp=0.001\n",
    "maxp=0.95\n",
    "vec6_count = CountVectorizer(tokenizer=tokenize,min_df=minp,max_df=maxp,ngram_range=(1,3),analyzer='word')\n",
    "vec6_idf =   TfidfVectorizer(tokenizer=tokenize,min_df=minp,max_df=maxp,ngram_range=(1,3),analyzer='word')\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=10)\n",
    "#hv.transform(corpus)\n",
    "vec=vec6_count\n",
    "\n",
    "#2# Specify the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#clf = MultinomialNB()\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn import svm\n",
    "#clf = svm.SVC()\n",
    "#n_neighbors = 15\n",
    "#clf = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "#clf = neighbors.RadiusNeighborsClassifier(n_neighbors)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "#3# Using pipelineing, the data transformations can chained together \n",
    "#and the last object is the estimator or model.\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "from sklearn import pipeline\n",
    "pipe = pipeline.Pipeline([('vectorizer', vec),\n",
    "                          ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=df['text']\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['category'])\n",
    "y=le.transform(df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.4,random_state=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.924 (+/- 0.011). Test Score: (0.924)\n"
     ]
    }
   ],
   "source": [
    "#6# Train the model using 5 fold cross validation and calculate the scores. \n",
    "train_scores = cross_validation.cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "#Fit the model\n",
    "pipe=pipe.fit(X_train, y_train)\n",
    "#Score the model on unseen test data  data\n",
    "test_score=pipe.score(X_test,y_test)\n",
    "\n",
    "#7# Print out the accuracy scores and \n",
    "print(\"Training Accuracy: %0.3f (+/- %0.3f). Test Score: (%0.3f)\" \n",
    "      % (train_scores.mean(), train_scores.std(),test_score))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = pipe.predict(df['text'])\n",
    "pred_labels = le.inverse_transform(y_predicted)\n",
    "act_labels = le.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['predicted'] = pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['score'] = (df['predicted'] == df['category'])\n",
    "df['hash'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temdf = df.drop(['text'], axis=1, level=None, inplace=False, errors='raise')\n",
    "temdf.head(5)\n",
    "temdf = temdf[temdf['file_id'] != 'x']\n",
    "temdf['category'] = temdf['category'].apply(lambda x: '' + str(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:2: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>score</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>295.0</td>\n",
       "      <td>8865.0</td>\n",
       "      <td>9160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earn</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3893.0</td>\n",
       "      <td>3923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acq</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>2292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crude</th>\n",
       "      <td>22.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade</th>\n",
       "      <td>22.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money-fx</th>\n",
       "      <td>36.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interest</th>\n",
       "      <td>17.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money-supply</th>\n",
       "      <td>11.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ship</th>\n",
       "      <td>11.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sugar</th>\n",
       "      <td>3.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "score         False    True     All\n",
       "category                           \n",
       "All           295.0  8865.0  9160.0\n",
       "earn           30.0  3893.0  3923.0\n",
       "acq            27.0  2265.0  2292.0\n",
       "crude          22.0   352.0   374.0\n",
       "trade          22.0   304.0   326.0\n",
       "money-fx       36.0   273.0   309.0\n",
       "interest       17.0   255.0   272.0\n",
       "money-supply   11.0   140.0   151.0\n",
       "ship           11.0   133.0   144.0\n",
       "sugar           3.0   119.0   122.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.pivot_table(temdf, values='hash', index='category', columns='score', aggfunc=np.sum, margins=True, fill_value=0)\n",
    "table = table.sort('All', ascending=False)\n",
    "table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score        False  True   All\n",
      "category                      \n",
      "copper         0.0  44.0  44.0\n",
      "cotton         0.0  24.0  24.0\n",
      "orange         0.0  22.0  22.0\n",
      "housing        0.0  17.0  17.0\n",
      "lei            0.0  14.0  14.0\n",
      "carcass        0.0  11.0  11.0\n",
      "instal-debt    0.0   6.0   6.0\n",
      "tea            0.0   5.0   5.0\n",
      "cpu            0.0   4.0   4.0\n",
      "jet            0.0   3.0   3.0\n",
      "naphtha        0.0   1.0   1.0\n",
      "l-cattle       0.0   1.0   1.0\n",
      "dmk            0.0   1.0   1.0\n",
      "hog            0.0   1.0   1.0\n",
      "rice           0.0   1.0   1.0\n",
      "rand           0.0   1.0   1.0\n",
      "propane        0.0   1.0   1.0\n"
     ]
    }
   ],
   "source": [
    "table.iloc[:,1] == table.iloc[:,2]\n",
    "print(table[table.iloc[:,1] == table.iloc[:,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score     False  True  All\n",
      "category                  \n",
      "coconut     1.0   0.0  1.0\n",
      "nzdlr       1.0   0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print(table[table.iloc[:,0] == table.iloc[:,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 3)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>category</th>\n",
       "      <th>part</th>\n",
       "      <th>predicted</th>\n",
       "      <th>score</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>[u'trade']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[trade]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/14828</td>\n",
       "      <td>[u'grain']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[grain]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/14839</td>\n",
       "      <td>[u'ship']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[ship]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/14842</td>\n",
       "      <td>[u'gold']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[gold]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test/14843</td>\n",
       "      <td>[u'acq']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[acq]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test/14844</td>\n",
       "      <td>[u'tin']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[naphtha]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test/14854</td>\n",
       "      <td>[u'ipi']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[ipi]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test/14859</td>\n",
       "      <td>[u'earn']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test/14860</td>\n",
       "      <td>[u'earn']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test/14865</td>\n",
       "      <td>[u'acq']</td>\n",
       "      <td>test/</td>\n",
       "      <td>[gold]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_id    category   part  predicted  score  hash\n",
       "1   test/14826  [u'trade']  test/    [trade]   True     1\n",
       "2   test/14828  [u'grain']  test/    [grain]   True     1\n",
       "3   test/14839   [u'ship']  test/     [ship]   True     1\n",
       "4   test/14842   [u'gold']  test/     [gold]   True     1\n",
       "5   test/14843    [u'acq']  test/      [acq]   True     1\n",
       "6   test/14844    [u'tin']  test/  [naphtha]  False     1\n",
       "7   test/14854    [u'ipi']  test/      [ipi]   True     1\n",
       "8   test/14859   [u'earn']  test/     [earn]   True     1\n",
       "9   test/14860   [u'earn']  test/     [earn]   True     1\n",
       "10  test/14865    [u'acq']  test/     [gold]  False     1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vec:  [Count vec] -> Accuracy: 0.92 (+/- 0.01) Test: 0.92  Model: [Stocastic Gradient]\n",
      "Vec:  [Count vec] -> Accuracy: 0.94 (+/- 0.01) Test: 0.94  Model: [Logistic Regression]\n",
      "Vec:  [Count vec] -> Accuracy: 0.84 (+/- 0.02) Test: 0.83  Model: [Random Forest]\n",
      "Vec:  [Count vec] -> Accuracy: 0.88 (+/- 0.02) Test: 0.88  Model: [naive Bayes]\n",
      "Vec:  [Count vec] -> Accuracy: 0.64 (+/- 0.01) Test: 0.66  Model: [svm]\n",
      "Vec:  [Count vec] -> Accuracy: 0.70 (+/- 0.02) Test: 0.73  Model: [knn]\n",
      "Vec:  [Count vec] -> Accuracy: 0.75 (+/- 0.04) Test: 0.73  Model: [nn mlp]\n",
      "Vec:  [Count vec] -> Accuracy: 0.91 (+/- 0.01) Test: 0.91  Model: [ensemble]\n",
      "Vec:  [tfidf vec] -> Accuracy: 0.87 (+/- 0.02) Test: 0.88  Model: [Stocastic Gradient]\n",
      "Vec:  [tfidf vec] -> Accuracy: 0.87 (+/- 0.02) Test: 0.88  Model: [Logistic Regression]\n",
      "Vec:  [tfidf vec] -> Accuracy: 0.84 (+/- 0.02) Test: 0.84  Model: [Random Forest]\n",
      "Vec:  [tfidf vec] -> Accuracy: 0.77 (+/- 0.02) Test: 0.78  Model: [naive Bayes]\n",
      "Vec:  [tfidf vec] -> Accuracy: 0.43 (+/- 0.01) Test: 0.42  Model: [svm]\n",
      "Vec:  [tfidf vec] -> Accuracy: 0.90 (+/- 0.01) Test: 0.91  Model: [knn]\n",
      "Vec:  [tfidf vec] -> Accuracy: 0.48 (+/- 0.10) Test: 0.42  Model: [nn mlp]\n",
      "Vec:  [tfidf vec] -> Accuracy: 0.87 (+/- 0.02) Test: 0.88  Model: [ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn import svm\n",
    "n_neighbors = 15\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = MultinomialNB()\n",
    "clf5 = svm.SVC()\n",
    "clf6 = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "clf7 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('mnb', clf4), ('svm', clf5),('knn', clf6), \n",
    "                                    ('mlp', clf7), ('sgd', clf)], voting='hard')\n",
    "vec6_count = CountVectorizer(tokenizer=tokenize,min_df=minp,max_df=maxp,ngram_range=(1,3),analyzer='word')\n",
    "vec6_idf =   TfidfVectorizer(tokenizer=tokenize,min_df=minp,max_df=maxp,ngram_range=(1,3),analyzer='word')\n",
    "\n",
    "for vec, vec_lab in zip([vec6_count, vec6_idf],['Count vec','tfidf vec']):\n",
    "    for clf, label in zip([clf, clf1, clf2, clf4, clf5, clf6, clf7, eclf], \n",
    "                          ['Stocastic Gradient','Logistic Regression', 'Random Forest', 'naive Bayes', \n",
    "                           'svm','knn','nn mlp', 'ensemble']):\n",
    "        pipe = pipeline.Pipeline([('vectorizer', vec),('clf', clf)])\n",
    "        train_scores = cross_validation.cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "        pipe=pipe.fit(X_train, y_train)\n",
    "        test_score=pipe.score(X_test,y_test)\n",
    "        print(\"Vec:  [%s] -> Accuracy: %0.2f (+/- %0.2f) Test: %0.2f  Model: [%s]\" \n",
    "              % (vec_lab, train_scores.mean(), train_scores.std(), test_score, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
